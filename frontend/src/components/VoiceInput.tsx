import { useState, useRef, useEffect } from 'react';

interface VoiceInputProps {
  onTranscript: (text: string) => void;
  onError?: (error: string) => void;
  placeholder?: string;
  className?: string;
  disabled?: boolean;
  autoStart?: boolean;
}

export default function VoiceInput({
  onTranscript,
  onError,
  placeholder = "ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥...",
  className = "",
  disabled = false,
  autoStart = false
}: VoiceInputProps) {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [isSupported, setIsSupported] = useState(false);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);

  // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
      setIsSupported(true);
      recognitionRef.current = new SpeechRecognition();
      
      // é…ç½®è¯­éŸ³è¯†åˆ«
      const recognition = recognitionRef.current;
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'zh-CN'; // æ”¯æŒä¸­æ–‡
      
      // è¯†åˆ«ç»“æœå¤„ç†
      recognition.onresult = (event) => {
        let finalTranscript = '';
        let interimTranscript = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          if (result.isFinal) {
            finalTranscript += result[0].transcript;
          } else {
            interimTranscript += result[0].transcript;
          }
        }
        
        const currentTranscript = finalTranscript || interimTranscript;
        setTranscript(currentTranscript);
        
        // å¦‚æœæœ‰æœ€ç»ˆç»“æœï¼Œé€šçŸ¥çˆ¶ç»„ä»¶
        if (finalTranscript) {
          onTranscript(finalTranscript.trim());
          
          // è‡ªåŠ¨åœæ­¢è¯†åˆ«ï¼ˆ3ç§’åï¼‰
          if (timeoutRef.current) {
            clearTimeout(timeoutRef.current);
          }
          timeoutRef.current = setTimeout(() => {
            stopListening();
          }, 3000);
        }
      };
      
      // é”™è¯¯å¤„ç†
      recognition.onerror = (event) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
        let errorMessage = 'è¯­éŸ³è¯†åˆ«å‡ºé”™';
        
        switch (event.error) {
          case 'no-speech':
            errorMessage = 'æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•';
            break;
          case 'audio-capture':
            errorMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£';
            break;
          case 'not-allowed':
            errorMessage = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»';
            break;
          case 'network':
            errorMessage = 'ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥';
            break;
          default:
            errorMessage = `è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`;
        }
        
        onError?.(errorMessage);
        setIsListening(false);
      };
      
      // è¯†åˆ«ç»“æŸ
      recognition.onend = () => {
        setIsListening(false);
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current);
        }
      };
      
      // è‡ªåŠ¨å¯åŠ¨
      if (autoStart && !disabled) {
        startListening();
      }
    } else {
      setIsSupported(false);
      onError?.('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½');
    }
    
    return () => {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
      if (recognitionRef.current && isListening) {
        recognitionRef.current.stop();
      }
    };
  }, [autoStart, disabled, onError, onTranscript, isListening]);

  const startListening = () => {
    if (!recognitionRef.current || disabled || isListening) return;
    
    try {
      setTranscript('');
      setIsListening(true);
      recognitionRef.current.start();
    } catch (error) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      onError?.('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥');
      setIsListening(false);
    }
  };

  const stopListening = () => {
    if (!recognitionRef.current || !isListening) return;
    
    try {
      recognitionRef.current.stop();
      setIsListening(false);
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
    } catch (error) {
      console.error('åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
    }
  };

  const toggleListening = () => {
    if (isListening) {
      stopListening();
    } else {
      startListening();
    }
  };

  if (!isSupported) {
    return (
      <div className={`flex items-center justify-center p-3 rounded-lg ${className}`} 
           style={{ 
             backgroundColor: 'var(--background-secondary)', 
             border: '1px solid var(--border-light)',
             color: 'var(--text-muted)'
           }}>
        <span className="text-sm">ğŸš« æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¾“å…¥</span>
      </div>
    );
  }

  return (
    <div className={`flex items-center space-x-3 p-3 rounded-xl ${className}`}
         style={{ 
           backgroundColor: 'var(--background-secondary)', 
           border: '1px solid var(--border-light)'
         }}>
      
      {/* æç®€è¯­éŸ³æŒ‰é’® */}
      <button
        onClick={toggleListening}
        disabled={disabled}
        className={`flex items-center justify-center w-8 h-8 rounded-lg transition-all ${
          isListening 
            ? 'animate-pulse' 
            : 'hover:scale-105'
        }`}
        style={{
          backgroundColor: isListening ? 'var(--error-bg)' : 'var(--primary-light)',
          color: isListening ? 'var(--error)' : 'var(--primary)',
          opacity: disabled ? 0.5 : 1,
          border: 'none'
        }}
        title={isListening ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹è¯­éŸ³è¾“å…¥'}
      >
        <span style={{ fontSize: '14px' }}>
          {isListening ? 'â¹ï¸' : 'ğŸ¤'}
        </span>
      </button>
      
      {/* æç®€çŠ¶æ€æ˜¾ç¤º */}
      <div className="flex-1 min-w-0">
        {isListening ? (
          <div className="flex items-center space-x-2">
            <div className="flex space-x-1">
              <div className="w-1.5 h-1.5 rounded-full animate-bounce" style={{ backgroundColor: 'var(--error)' }}></div>
              <div className="w-1.5 h-1.5 rounded-full animate-bounce" style={{ backgroundColor: 'var(--error)', animationDelay: '0.1s' }}></div>
              <div className="w-1.5 h-1.5 rounded-full animate-bounce" style={{ backgroundColor: 'var(--error)', animationDelay: '0.2s' }}></div>
            </div>
            <span className="text-xs font-medium" style={{ color: 'var(--error)' }}>
              æ­£åœ¨å¬å–...
            </span>
          </div>
        ) : (
          <span className="text-xs" style={{ color: 'var(--text-muted)' }}>
            {placeholder}
          </span>
        )}
        
        {/* æç®€è½¬å½•ç»“æœ */}
        {transcript && (
          <div className="mt-2 p-2 rounded-lg" 
               style={{ 
                 backgroundColor: 'var(--card-background)',
                 border: '1px solid var(--border-light)'
               }}>
            <p className="text-xs" style={{ color: 'var(--text-primary)' }}>
              {transcript}
            </p>
          </div>
        )}
      </div>
      
      {/* æç®€è¯­è¨€åˆ‡æ¢ */}
      <select
        value={recognitionRef.current?.lang || 'zh-CN'}
        onChange={(e) => {
          if (recognitionRef.current) {
            recognitionRef.current.lang = e.target.value;
          }
        }}
        disabled={disabled || isListening}
        className="px-2 py-1 text-xs rounded-lg border-0 transition-all"
        style={{
          backgroundColor: 'var(--background-secondary)',
          color: 'var(--text-muted)',
          fontSize: '10px'
        }}
        title="é€‰æ‹©è¯­éŸ³è¯†åˆ«è¯­è¨€"
      >
        <option value="zh-CN">ä¸­</option>
        <option value="en-US">En</option>
        <option value="ja-JP">æ—¥</option>
        <option value="ko-KR">í•œ</option>
      </select>
    </div>
  );
}

// ç±»å‹å£°æ˜
declare global {
  interface Window {
    SpeechRecognition: typeof SpeechRecognition;
    webkitSpeechRecognition: typeof SpeechRecognition;
  }
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  onresult: (event: SpeechRecognitionEvent) => void;
  onerror: (event: SpeechRecognitionErrorEvent) => void;
  onend: () => void;
}

interface SpeechRecognitionEvent {
  resultIndex: number;
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent {
  error: string;
}

interface SpeechRecognitionResultList {
  length: number;
  [index: number]: SpeechRecognitionResult;
}

interface SpeechRecognitionResult {
  isFinal: boolean;
  [index: number]: SpeechRecognitionAlternative;
}

interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}

declare var SpeechRecognition: {
  prototype: SpeechRecognition;
  new(): SpeechRecognition;
};
